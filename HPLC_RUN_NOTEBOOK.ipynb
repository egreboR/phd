{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% LE PLAN\n",
    "\n",
    "'''\n",
    "    1. df reorganisation (factorial) and creation of ratios\n",
    "    2. calculate and save to table average, SD and SEM\n",
    "    3. ShapiroWilk test for normailty (note if not noirmal) and statistical analysis\n",
    "    4. plot histograms with SEM and ** for each treatment, compound and BR\n",
    "    5. test normaility for correlation if normal : \n",
    "                                                    --> pearson product coirrelation plots \n",
    "                            non-parametric data :\n",
    "                                                    --> spearman coirrelation plots      \n",
    "                                                    \n",
    "            produced for each BR comparing compunds and compound comparing BR\n",
    "    6. PCA for  complete compound_BR/ ratio_BR sets between groups \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Constants:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import module HPLC_MODULE_NOTEBOOK\n",
    "\n",
    "Set filename to .csv with data structure\n",
    "            'mouse_no' 'group_no' 'compound_BR'\n",
    "                1           2           ng_mg\n",
    "\n",
    "Set \n",
    "    treatment_mapping: 'string' corresponging to each group_no /treatment_group\n",
    "    compound_ratio_mapping: dictionary of the ratios of interest \n",
    "    palette_labeled: colour palette mapping 'strings' to colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREATMENT MAPPING {1: 'vehicles', 2: '10mg/kgTCB', 3: '3mg/kgTCB', 4: '0.3mg/kgTCB', 5: 'TCB+MDL', 6: '0.2mg/kgMDL'} SAVED TO /Users/jasminebutler/Desktop/phd/input/cache/TCB2_data_HPLC SUBCACHE\n",
      "GETTING \"ratios_df\" FROM \"TCB2_data_HPLC\" CACHE\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m setTreatment(filename, treatment_mapping) \u001b[39m#inputing group info REMI: make a singl dict input including all the above\u001b[39;00m\n\u001b[1;32m     23\u001b[0m ratios_df \u001b[39m=\u001b[39m getRatiosDf(filename) \u001b[39m#get ratio df and save to cashe \u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m getRatiosPerRegion(ratios_df, compound_ratio_mapping) \u001b[39m#ratios of interest \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/phd/HPLC_MODULE_NOTEBOOK.py:141\u001b[0m, in \u001b[0;36mgetRatiosPerRegion\u001b[0;34m(filename, ratios_mapping)\u001b[0m\n\u001b[1;32m    139\u001b[0m cache_filename \u001b[39m=\u001b[39m dictToFilename(ratios_mapping)\n\u001b[1;32m    140\u001b[0m builder_callback_with_param \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(buildRatiosPerRegionDf, ratios_mapping\u001b[39m=\u001b[39mratios_mapping)\n\u001b[0;32m--> 141\u001b[0m \u001b[39mreturn\u001b[39;00m getOrBuildDf(filename, cache_filename, builder_callback_with_param)\n",
      "File \u001b[0;32m~/Desktop/phd/HPLC_MODULE_NOTEBOOK.py:120\u001b[0m, in \u001b[0;36mgetOrBuildDf\u001b[0;34m(filename, df_identifier, builder_cb)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetOrBuildDf\u001b[39m(filename, df_identifier, builder_cb):\n\u001b[0;32m--> 120\u001b[0m     filename_no_extension \u001b[39m=\u001b[39m filename\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m isCached(filename_no_extension, df_identifier): \u001b[39m#Check cache to avoid recalcuating from scratch if alreasy done\u001b[39;00m\n\u001b[1;32m    122\u001b[0m         \u001b[39mreturn\u001b[39;00m getCache(filename_no_extension, df_identifier)\n",
      "File \u001b[0;32m~/Desktop/phd/.venv/lib/python3.9/site-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "from HPLC_MODULE_NOTEBOOK import * #Must be reimported when changes made to module file\n",
    "\n",
    "filename = 'TCB2_data_HPLC.csv'  # TCB2 #using current working directory plus file name \n",
    "\n",
    "treatment_mapping = { #TO DO : change name to treatment_info and add columns in df REMI\n",
    "    1: {'name': 'vehicles', 'color': \"white\", 'experiments': ['dose_responce','agonist_antagonist']},\n",
    "    2: {'name': '10mg/kgTCB', 'color': \"firebrick\", 'experiments': ['dose_responce']},\n",
    "    3: {'name': '3mg/kgTCB', 'color': \"red\", 'experiments': ['dose_responce','agonist_antagonist']},\n",
    "    4: {'name': '0.3mg/kgTCB', 'color': \"salmon\", 'experiments': ['dose_responce']},\n",
    "    5: {'name': 'TCB+MDL', 'color': \"grey\", 'experiments': ['agonist_antagonist']},\n",
    "    6: {'name': '0.2mg/kgMDL', 'color': \"black\", 'experiments': ['agonist_antagonist']}\n",
    "    } \n",
    "compound_ratio_mapping = {'DOPAC': ['DA'],     \n",
    "                       '5HIAA': ['5HT'],\n",
    "                       '3MT': ['DA'],\n",
    "                       'HVA': ['DA', '3MT', 'DOPAC'],\n",
    "                       'GLN': ['GLU']}\n",
    "\n",
    "experimantal_info = {'experiment1': {'groups':[1,2,3,4], 'independant_var': ['TCB2']}, \n",
    "                     'experiment2':{'groups':[1,3,5,6], 'independant_var': ['TCB2', 'MDL']}}\n",
    "\n",
    "# treatment_mapping = {1: 'vehicles', 2: '10mg/kgTCB', 3: '3mg/kgTCB',\n",
    "#                   4: '0.3mg/kgTCB', 5: 'TCB+MDL', 6: '0.2mg/kgMDL'} \n",
    "\n",
    "# palette_labeled = {'vehicles': \"white\",  # TCB2\n",
    "#                    '10mg/kgTCB': \"firebrick\",\n",
    "#                    '3mg/kgTCB': \"red\",\n",
    "#                    '0.3mg/kgTCB': \"salmon\",\n",
    "#                    'TCB+MDL': \"grey\",\n",
    "#                    '0.2mg/kgMDL': \"black\"}\n",
    "\n",
    "setTreatment(filename, treatment_mapping) #inputing group info REMI: make a singl dict input including all the above\n",
    "ratios_df = getRatiosDf(filename) #get ratio df and save to cashe \n",
    "getRatiosPerRegion(ratios_df, compound_ratio_mapping) #ratios of interest \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclusion of outliers Grubbs test or Rout: to be done for each group i.e. BR, compound, treatment(group) RATIOS and nm_mg seperatly\n",
    "    #select method: Grubbs\n",
    "    #propose outliers and show on plot with group: \n",
    "    #accept or reject \n",
    "    #modity df and save something indicating removed data \n",
    "\n",
    "#REMI: for now I am jus not doing this as it feels complicated\n",
    "#from outliers import smirnov_grubbs as grubbs\n",
    "#x_ = grubbs.test(x, alpha=p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate Stats:\n",
    "    build a df with the shapiro_F, shapiro_p, mean, SD, SEM, list of values(good for hist plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING \"compound_aggregate_stats\" FROM \"TCB2_data_HPLC\" CACHE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>BR</th>\n",
       "      <th>compound</th>\n",
       "      <th>shapiro_F</th>\n",
       "      <th>shapiro_p</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2mg/kgMDL</td>\n",
       "      <td>AC</td>\n",
       "      <td>5HIAA</td>\n",
       "      <td>0.931388</td>\n",
       "      <td>0.461682</td>\n",
       "      <td>True</td>\n",
       "      <td>0.116859</td>\n",
       "      <td>0.036906</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>[0.129558874, 0.103243639, 0.137603989, 0.0736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2mg/kgMDL</td>\n",
       "      <td>AC</td>\n",
       "      <td>5HT</td>\n",
       "      <td>0.980960</td>\n",
       "      <td>0.970100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.099423</td>\n",
       "      <td>0.025240</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>[0.121272649, 0.092282145, 0.083923844, 0.0579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2mg/kgMDL</td>\n",
       "      <td>AC</td>\n",
       "      <td>5HTP</td>\n",
       "      <td>0.592687</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>True</td>\n",
       "      <td>0.039143</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>[0.017717292, 0.003593031, 0.013304998, 0.0129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2mg/kgMDL</td>\n",
       "      <td>AC</td>\n",
       "      <td>A</td>\n",
       "      <td>0.864360</td>\n",
       "      <td>0.085876</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>[0.003197882, 0.000260697, 0.003253498, 0.0012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2mg/kgMDL</td>\n",
       "      <td>AC</td>\n",
       "      <td>ALA</td>\n",
       "      <td>0.941838</td>\n",
       "      <td>0.573636</td>\n",
       "      <td>True</td>\n",
       "      <td>39.520359</td>\n",
       "      <td>10.047596</td>\n",
       "      <td>3.177329</td>\n",
       "      <td>[34.43540514, 51.0982753, 53.46436707, 37.4013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>vehicles</td>\n",
       "      <td>vH</td>\n",
       "      <td>LSER</td>\n",
       "      <td>0.842247</td>\n",
       "      <td>0.033795</td>\n",
       "      <td>True</td>\n",
       "      <td>47.996985</td>\n",
       "      <td>20.257171</td>\n",
       "      <td>6.107767</td>\n",
       "      <td>[72.36113476, 46.51357707, 36.73766809, 33.418...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>vehicles</td>\n",
       "      <td>vH</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.947636</td>\n",
       "      <td>0.613907</td>\n",
       "      <td>True</td>\n",
       "      <td>0.232054</td>\n",
       "      <td>0.042271</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>[0.218822744, 0.221792856, 0.170609889, 0.2410...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>vehicles</td>\n",
       "      <td>vH</td>\n",
       "      <td>TAU</td>\n",
       "      <td>0.903503</td>\n",
       "      <td>0.203894</td>\n",
       "      <td>True</td>\n",
       "      <td>475.116293</td>\n",
       "      <td>181.685197</td>\n",
       "      <td>54.780148</td>\n",
       "      <td>[720.2194902, 486.7247508, 368.057951, 314.336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>vehicles</td>\n",
       "      <td>vH</td>\n",
       "      <td>THR</td>\n",
       "      <td>0.842565</td>\n",
       "      <td>0.034120</td>\n",
       "      <td>True</td>\n",
       "      <td>17.937869</td>\n",
       "      <td>7.332683</td>\n",
       "      <td>2.210887</td>\n",
       "      <td>[28.51172535, 16.52169516, 14.81929198, 12.815...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>vehicles</td>\n",
       "      <td>vH</td>\n",
       "      <td>TYR</td>\n",
       "      <td>0.838977</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>True</td>\n",
       "      <td>11.523438</td>\n",
       "      <td>5.214638</td>\n",
       "      <td>1.738213</td>\n",
       "      <td>[12.62693417, 8.102282762, 7.853070894, 9.4895...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3866 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        treatment  BR compound  shapiro_F  shapiro_p  is_valid        mean   \n",
       "0     0.2mg/kgMDL  AC    5HIAA   0.931388   0.461682      True    0.116859  \\\n",
       "1     0.2mg/kgMDL  AC      5HT   0.980960   0.970100      True    0.099423   \n",
       "2     0.2mg/kgMDL  AC     5HTP   0.592687   0.000045      True    0.039143   \n",
       "3     0.2mg/kgMDL  AC        A   0.864360   0.085876      True    0.002212   \n",
       "4     0.2mg/kgMDL  AC      ALA   0.941838   0.573636      True   39.520359   \n",
       "...           ...  ..      ...        ...        ...       ...         ...   \n",
       "3861     vehicles  vH     LSER   0.842247   0.033795      True   47.996985   \n",
       "3862     vehicles  vH       NA   0.947636   0.613907      True    0.232054   \n",
       "3863     vehicles  vH      TAU   0.903503   0.203894      True  475.116293   \n",
       "3864     vehicles  vH      THR   0.842565   0.034120      True   17.937869   \n",
       "3865     vehicles  vH      TYR   0.838977   0.056260      True   11.523438   \n",
       "\n",
       "             std        sem                                             values  \n",
       "0       0.036906   0.011671  [0.129558874, 0.103243639, 0.137603989, 0.0736...  \n",
       "1       0.025240   0.007981  [0.121272649, 0.092282145, 0.083923844, 0.0579...  \n",
       "2       0.062978   0.019915  [0.017717292, 0.003593031, 0.013304998, 0.0129...  \n",
       "3       0.002081   0.000658  [0.003197882, 0.000260697, 0.003253498, 0.0012...  \n",
       "4      10.047596   3.177329  [34.43540514, 51.0982753, 53.46436707, 37.4013...  \n",
       "...          ...        ...                                                ...  \n",
       "3861   20.257171   6.107767  [72.36113476, 46.51357707, 36.73766809, 33.418...  \n",
       "3862    0.042271   0.012745  [0.218822744, 0.221792856, 0.170609889, 0.2410...  \n",
       "3863  181.685197  54.780148  [720.2194902, 486.7247508, 368.057951, 314.336...  \n",
       "3864    7.332683   2.210887  [28.51172535, 16.52169516, 14.81929198, 12.815...  \n",
       "3865    5.214638   1.738213  [12.62693417, 8.102282762, 7.853070894, 9.4895...  \n",
       "\n",
       "[3866 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "getCompoundAggregateStatsDf(filename) #display aggregate stats \n",
    "\n",
    "#normality testing: shapiro wilk\n",
    "    #display what % of data sets (i.e. BR, compound, treatment(group)) are normal\n",
    "    #chose to go parametric or non from here (all data treated same)\n",
    "    #set in dict of stuffs.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING \"compound_df\" FROM \"TCB2_data_HPLC\" CACHE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>BR</th>\n",
       "      <th>compound</th>\n",
       "      <th>ng_mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>OF</td>\n",
       "      <td>ASP</td>\n",
       "      <td>86.863115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>OF</td>\n",
       "      <td>GLU</td>\n",
       "      <td>509.836736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>OF</td>\n",
       "      <td>ASPN</td>\n",
       "      <td>2.842720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>OF</td>\n",
       "      <td>HIS</td>\n",
       "      <td>7.785802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>OF</td>\n",
       "      <td>LSER</td>\n",
       "      <td>37.902285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39930</th>\n",
       "      <td>70</td>\n",
       "      <td>10mg/kgTCB</td>\n",
       "      <td>CE</td>\n",
       "      <td>DOPAC</td>\n",
       "      <td>0.029512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39931</th>\n",
       "      <td>70</td>\n",
       "      <td>10mg/kgTCB</td>\n",
       "      <td>CE</td>\n",
       "      <td>DA</td>\n",
       "      <td>0.026709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39932</th>\n",
       "      <td>70</td>\n",
       "      <td>10mg/kgTCB</td>\n",
       "      <td>CE</td>\n",
       "      <td>5HIAA</td>\n",
       "      <td>0.074892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39933</th>\n",
       "      <td>70</td>\n",
       "      <td>10mg/kgTCB</td>\n",
       "      <td>CE</td>\n",
       "      <td>HVA</td>\n",
       "      <td>0.035113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39934</th>\n",
       "      <td>70</td>\n",
       "      <td>10mg/kgTCB</td>\n",
       "      <td>CE</td>\n",
       "      <td>5HT</td>\n",
       "      <td>0.109190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39935 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mouse_id   treatment  BR compound       ng_mg\n",
       "0             2    vehicles  OF      ASP   86.863115\n",
       "1             2    vehicles  OF      GLU  509.836736\n",
       "2             2    vehicles  OF     ASPN    2.842720\n",
       "3             2    vehicles  OF      HIS    7.785802\n",
       "4             2    vehicles  OF     LSER   37.902285\n",
       "...         ...         ...  ..      ...         ...\n",
       "39930        70  10mg/kgTCB  CE    DOPAC    0.029512\n",
       "39931        70  10mg/kgTCB  CE       DA    0.026709\n",
       "39932        70  10mg/kgTCB  CE    5HIAA    0.074892\n",
       "39933        70  10mg/kgTCB  CE      HVA    0.035113\n",
       "39934        70  10mg/kgTCB  CE      5HT    0.109190\n",
       "\n",
       "[39935 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantitative Analysis \n",
    "#reference for stats: https://www.statology.org/tukey-test-python/\n",
    "\n",
    "#remi: here i need to build in flexable stats structure\n",
    "#group to compare: if data conatins multiple experiments then there may be groupings i.e. doese/responce and agonist/antagonist\n",
    "#normailty: nomal/parametric or not\n",
    "#independant vairables (factor): i.e. k=2 (this will belong to each experiment or grouping)\n",
    "        #dose responce data (single factor k=1) --> one way ANOVA --> post hoc Tukey \n",
    "        #agonist antagonist data ( k=2) --> two way ANOVA --> one way ANOVA --> post hoc Tukey\n",
    "        #(multi factor k=3)repeated measures ANOVA \n",
    "#post hoc: tukey \n",
    "#significance plotted: e.g. tukey after passing BOTH one and two way ANOVA or all one way ANOVA tukey \n",
    "\n",
    "\n",
    "# #oneway (df, group_to_compare):\n",
    "# #inputs: array like groups e.g. group1,group2,group3,group4\n",
    "# #outputs two floats : F_value, p_value \n",
    "# #if p<0.05 the two groups do not have the same population mean \n",
    "# F_value, p_value = scipy.stats.f_oneway(group1,group2,group3,group4)\n",
    "\n",
    "# #two way anova (df, group_to_compare):\n",
    "# #inputs: df, dv='ng_mg', between= [factor_1, factor_2] #the factors should be boolian columns i.e. TCB2 = T/F and MDL = T/F\n",
    "# #outputs: df see https://pingouin-stats.org/build/html/generated/pingouin.anova.html\n",
    "#         # \tSource\tSS\tDF\tMS\tF\tp-unc\tnp2\n",
    "#         # 0\tANT_MDL\t0.001\t1\t0.001\t0.053\t0.819\t0.001\n",
    "#         # 1\tAG_TCB2\t0.007\t1\t0.007\t0.671\t0.418\t0.017\n",
    "#         # 2\tANT_MDL * AG_TCB2\t0.012\t1\t0.012\t1.123\t0.296\t0.028\n",
    "#         # 3\tResidual\t0.415\t39\t0.011\t\t\t\n",
    "\n",
    "# two_way_anova = pg.anova(data=df_anova_working, dv='dv', between=[\n",
    "#                                       ('ANT_MDL'), ('AG_TCB2')], detailed=True).round(3)\n",
    "\n",
    "# #tukey  --- post hoc DONE ON SITE AFTER ONE AND TWO WAY ARE IN DF to plot\n",
    "# #input df'ng_mg', df'grouping'\n",
    "# mc = MultiComparison(\n",
    "#     df_dose_responce[comp, BR], df_dose_responce['group', 'no'])\n",
    "# mc_results = mc.tukeyhsd()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #old df structure for input to two way ANOVA\n",
    "# d = {'dv': df_factors[comp, BR][indexes_to_keep], 'ANT_MDL': df_factors['ANT', 'MDL'][indexes_to_keep],\n",
    "#                   'AG_TCB2': df_factors['AG', 'TCB2'][indexes_to_keep], 'group': df_factors['group', 'no'][indexes_to_keep]}\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#histograms with stats plotted (idealy chosing the level of stats i.e. significance in two way ANOVA and one way ANOVA )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitative / Correlations:\n",
    "\n",
    "    clasical_corellogram                            #cell bellow is the first functioning draft of this for within compound\n",
    "                                                    #needs to be modularised and have inputs n_minimum, p_val, BR_column_order, compounds_of_interest \n",
    "                                                    #I would sugest we have a BR and a compound input to the function to chose which to look at and maybe a generate and save all option if needed\n",
    "        within BR       /       within compound\n",
    "\n",
    "    bar_corellogram\n",
    "                                                    #see whatsapp image 3/5/23\n",
    "        within BR       /       within compound\n",
    "\n",
    "    square_correlogram\n",
    "        within BR       /       within compound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING \"compound_df\" FROM \"TCB2_data_HPLC\" CACHE\n",
      "0.2mg/kgMDL for 3MT columns removed by n_minimum cut: ['SL1', 'VPL', 'SN']\n",
      "0.2mg/kgMDL for A columns removed by n_minimum cut: ['V', 'DG']\n",
      "0.2mg/kgMDL for ASPN columns removed by n_minimum cut: ['SJ']\n",
      "0.2mg/kgMDL for TYR columns removed by n_minimum cut: ['M', 'SJ', 'SL6', 'SR6', 'MD', 'DG', 'SN', 'MR']\n",
      "0.3mg/kgTCB for 3MT columns removed by n_minimum cut: ['SJ', 'SL6', 'dH', 'VPL']\n",
      "0.3mg/kgTCB for 5HTP columns removed by n_minimum cut: ['SJ']\n",
      "0.3mg/kgTCB for A columns removed by n_minimum cut: ['V', 'DG']\n",
      "0.3mg/kgTCB for ASPN columns removed by n_minimum cut: ['SJ']\n",
      "0.3mg/kgTCB for TYR columns removed by n_minimum cut: ['M', 'SJ', 'SL6', 'dH', 'VM', 'MD', 'DG', 'SN', 'CE']\n",
      "10mg/kgTCB for 3MT columns removed by n_minimum cut: ['dH']\n",
      "10mg/kgTCB for A columns removed by n_minimum cut: ['M', 'V', 'DG']\n",
      "10mg/kgTCB for ASPN columns removed by n_minimum cut: ['SJ']\n",
      "10mg/kgTCB for LDOPA columns removed by n_minimum cut: ['M']\n",
      "10mg/kgTCB for TYR columns removed by n_minimum cut: ['OF', 'M', 'SJ', 'SL6', 'SR6', 'vH', 'VM', 'MD', 'VPL', 'DG', 'SN', 'MR', 'CE']\n",
      "10mg/kgTCB for VMA columns removed by n_minimum cut: ['M']\n",
      "3mg/kgTCB for 3MT columns removed by n_minimum cut: ['dH', 'VPL']\n",
      "3mg/kgTCB for A columns removed by n_minimum cut: ['M', 'V']\n",
      "3mg/kgTCB for ASPN columns removed by n_minimum cut: ['SJ']\n",
      "3mg/kgTCB for TYR columns removed by n_minimum cut: ['OF', 'SR6', 'dH', 'vH', 'VM', 'MD', 'VPL', 'DG', 'SN', 'MR', 'CE']\n",
      "TCB+MDL for 3MT columns removed by n_minimum cut: ['SL1']\n",
      "TCB+MDL for A columns removed by n_minimum cut: ['V', 'DG']\n",
      "TCB+MDL for ASPN columns removed by n_minimum cut: ['SJ']\n",
      "TCB+MDL for LDOPA columns removed by n_minimum cut: ['M']\n",
      "TCB+MDL for TYR columns removed by n_minimum cut: ['M', 'SJ', 'SL6', 'SR6', 'dH', 'VM', 'VPL', 'DG', 'SN', 'VTA', 'MR', 'CE']\n",
      "TCB+MDL for VMA columns removed by n_minimum cut: ['M']\n",
      "vehicles for 3MT columns removed by n_minimum cut: ['SL1', 'dH', 'SN']\n",
      "vehicles for A columns removed by n_minimum cut: ['M', 'V']\n",
      "vehicles for ASPN columns removed by n_minimum cut: ['SJ']\n",
      "vehicles for LDOPA columns removed by n_minimum cut: ['M']\n",
      "vehicles for TYR columns removed by n_minimum cut: ['OF', 'SJ', 'SL6', 'SR6', 'MD', 'VPL', 'DG', 'SN', 'MR']\n",
      "vehicles for VMA columns removed by n_minimum cut: ['M']\n"
     ]
    }
   ],
   "source": [
    "df = getCompoundDf(filename)\n",
    "\n",
    "def calculate_pvalues(df):\n",
    "    '''Calculates p values from a pearson correlation\n",
    "        output is a square df of p values comparing column to column of origional df'''\n",
    "\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')  # creating empty df\n",
    "\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            # count Nans in list, if not 0 then cleaning needed\n",
    "            Nan_r = df[r].isnull().sum()\n",
    "            Nan_c = df[c].isnull().sum()\n",
    "\n",
    "            if Nan_r or Nan_c > 0:\n",
    "                print('unequal length data, trimming nans')\n",
    "                print('NaN count: ', Nan_r, ' =  ',\n",
    "                      r, ' and ', Nan_c, ' = ', c)\n",
    "\n",
    "                index_nan_r = df[df[r].isnull(\n",
    "                )].index.tolist()\n",
    "                clean_r = df[r].drop(index=index_nan_r)\n",
    "                clean_c = df[c].drop(index=index_nan_r)\n",
    "                Nan_clean_c = clean_c.isnull().sum()\n",
    "\n",
    "                if Nan_clean_c > 0:  # if we still have Nans in the other column\n",
    "                    index_nan_c = df[df[c].isnull(\n",
    "                    )].index.tolist()\n",
    "                    # only deleting indexes that have not been removed\n",
    "                    index_nan_c_no_duplicates = [\n",
    "                        x for x in index_nan_c if x not in index_nan_r]\n",
    "                    clean_r = clean_r.drop(index=index_nan_c_no_duplicates)\n",
    "                    clean_c = clean_c.drop(index=index_nan_c_no_duplicates)\n",
    "                    print('both trimmed, length = ', len(clean_r),)\n",
    "\n",
    "                else:\n",
    "                    print('trimed length = ', len(clean_r))\n",
    "\n",
    "            else:\n",
    "                clean_r = df[r]\n",
    "                clean_c = df[c]\n",
    "\n",
    "            df[r]\n",
    "            pvalues[r][c] = scipy.stats.pearsonr(clean_r, clean_c)[1]\n",
    "\n",
    "    pvalues = pvalues.dropna(axis=1, how='all') # removing collums the rows that have all 'NaN' values\n",
    "    pvalues = pvalues.dropna(axis=0, how='all')\n",
    "    return pvalues\n",
    "\n",
    "\n",
    "BR_column_order = ['OF', 'PL', 'CC', 'IC', 'M', 'SJ', 'SL1', 'SR1', 'SL6', 'SR6', 'AC', 'V' , \n",
    "            'Am', 'dH', 'vH', 'NAc', 'VM', 'DM', 'VL', 'DL', 'MD', 'VPL', 'VPR', 'DG', \n",
    "            'Y', 'SC', 'SN', 'VTA', 'DR', 'MR', 'CE' ] \n",
    "\n",
    "\n",
    "\n",
    "#within a compound between BRs\n",
    "for treatment_compound, treatment_compound_groupby_df in df.groupby(by =['treatment', 'compound']):\n",
    "    treatment = treatment_compound[0]\n",
    "    compound = treatment_compound[1]\n",
    "    #create df_to_correlate: index as mouse number, column as BR, ng_mg and NaN where data missing \n",
    "\n",
    "    BR_list= treatment_compound_groupby_df['BR'].unique().tolist() #get brain regions with any data from df\n",
    "    \n",
    "    \n",
    "    # if BR_column_order = True: ## will add order as a potional vairable \n",
    "    BR_list = [x for x in BR_column_order if x in BR_list]\n",
    "    # print(f'reordered BR_list for {treatment} within {compound} : {BR_list}')\n",
    "\n",
    "    mouse_list = treatment_compound_groupby_df['mouse_id'].unique().tolist() \n",
    "    df_to_correlate = pd.DataFrame(np.NaN, index=mouse_list, columns=BR_list) #create empty df \n",
    "    #fill df_to_correlate\n",
    "    for single_BR in BR_list: \n",
    "        BR_df = treatment_compound_groupby_df.loc[treatment_compound_groupby_df['BR'] == single_BR]#, 'ng_mg', 'mouse_ID'] #returns series with just ng_mg for BR\n",
    "        for row_ind, row in BR_df.iterrows():  #row is a series that can be called row['colname']\n",
    "            df_to_correlate.at[row['mouse_id'],single_BR]= row['ng_mg']\n",
    "\n",
    "    \n",
    "    #remove columns with n< n_minimum i.e. 6\n",
    "    df_to_correlate = df_to_correlate[[col for col in df_to_correlate.columns if df_to_correlate[col].count() > 5]] #generalise to (n_minimum - 1)\n",
    "    removed_columns = [i for i in BR_list if i not in df_to_correlate.columns]\n",
    "    if len(removed_columns) > 0:\n",
    "        print(f'{treatment} for {compound} columns removed by n_minimum cut: {removed_columns}')\n",
    "\n",
    "    #do correlations WORKING\n",
    "    corr_matrix_BR = df_to_correlate.corr('pearson', min_periods=1)\n",
    "\n",
    "\n",
    "    p_value_matrix = calculate_pvalues(corr_matrix_BR)  \n",
    "    \n",
    "    #plot shit #this runs but the figures dont get spat out? REMI WHYYYY\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    mask = np.invert(np.tril(p_value_matrix < 0.05)) #generalise p_value = 0.05\n",
    "\n",
    "    heatmap = sns.heatmap(corr_matrix_BR, vmin=-1, vmax=1,\n",
    "                            annot=True, cmap='BrBG', mask=mask, annot_kws={\"size\": 8})\n",
    "    heatmap.set_title(\n",
    "        compound+'  in  ' + treatment, fontdict={'fontsize': 18}, pad=12)\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within a BR between compounds\n",
    "# for treatment_BR, treatment_BR_groupby_df in df.groupby(by =['treatment', 'BR']):\n",
    "#     print(treatment_BR_groupby_df)\n",
    "    #create corr_df with a column for each compound beloning to the group\n",
    "\n",
    "##REMI: I believe we could be smart and have one series of modular functions that does both... thoughts?\n",
    "# Also wahat do I do with the figures I generate? they are too much to be spat out of a cell and need to be organised in a way that makes sense... a df of figures?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
